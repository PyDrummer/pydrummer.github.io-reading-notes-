# Linear Regressions

This article talks about using Scikit-learn, which is a powerful Python module for machine learning.

They use a dataset from Boston Housing that contains housing values.

As usual, they begin with importing the dependancies.

They use numpy, pandas, scipy.stats, matplotlib and sklearn.

The goal of this article/project is to predict the housing prices.

They seperate the data into a pandas dataframe. Next they use the scikit learn module with a linear regression model to predict prices.

By using LinearRegression.predict() they are able to predict a linear model with estimated coefficients.

Next they show a matplotlib of their rooms per house, and the cost on a scatter plot.

<img src="https://bigdata-madesimple.com/wp-content/uploads/2016/04/Relationship-between-RM-and-Price.png">

Now the .prediction() from earlier comes into play:

<img src="https://bigdata-madesimple.com/wp-content/uploads/2016/04/lm-predict.png">

And here are it's results for the next 5 predicted house's prices:

<img src="https://bigdata-madesimple.com/wp-content/uploads/2016/04/Prices-vs-predicted-prices.png">

Since this data has some error in the predictions they calculate a mean square error.

The data is still not perfect so they explain the train-test split.

> I am going to build a linear regression model using my train-test data sets.

- Input:

print “Fit a model X_train, and calculate MSE with Y_train:”, np.mean((Y_train – lm.predict(X_train)) ** 2)

print “Fit a model X_train, and calculate MSE with X_test, Y_test:”, np.mean((Y_test – lm.predict(X_test)) ** 2)

- Output:

Fit a model X_train, and calculate MSE with Y_train: 19.5467584735 Fit a model X_train, and calculate MSE with X_test, Y_test: 28.5413672756

### Using Residual Plots

Residual plots are used to visualize the erros in the data.

<img src="https://bigdata-madesimple.com/wp-content/uploads/2016/04/Residual-plot.png">
